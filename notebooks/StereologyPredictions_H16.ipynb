{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:14:06.384108Z",
     "iopub.status.busy": "2024-06-19T19:14:06.383110Z",
     "iopub.status.idle": "2024-06-19T19:14:11.629223Z",
     "shell.execute_reply": "2024-06-19T19:14:11.629223Z",
     "shell.execute_reply.started": "2024-06-19T19:14:06.384108Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34628\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import normalize, to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.pardir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import datasets\n",
    "from models import get_model\n",
    "from utils import resize_density_map, sliding_window_predict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "truncation = 4\n",
    "reduction = 8\n",
    "granularity = \"fine\"\n",
    "anchor_points = \"average\"\n",
    "\n",
    "model_name = \"clip_vit_b_16\"\n",
    "input_size = 224\n",
    "window_size = 16#224\n",
    "stride = 16#224 #Usado con sliding window (PARECE FUNCIONAR MUCHO MEJOR EN LAS PREDICCIONES [mirar texto negro sobre las imagenes])\n",
    "#stride=None \n",
    "weight_count_loss = 1.0\n",
    "count_loss = \"dmcount\"\n",
    "\n",
    "# Comment the lines below to test non-CLIP models.\n",
    "prompt_type = \"word\"\n",
    "num_vpt = 32\n",
    "vpt_drop = 0.\n",
    "deep_vpt = True\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:14:11.646194Z",
     "iopub.status.busy": "2024-06-19T19:14:11.646194Z",
     "iopub.status.idle": "2024-06-19T19:14:11.653379Z",
     "shell.execute_reply": "2024-06-19T19:14:11.653379Z",
     "shell.execute_reply.started": "2024-06-19T19:14:11.646194Z"
    }
   },
   "outputs": [],
   "source": [
    "#CARGO LOS PUNTOS DE HINRICHS: \n",
    "#(Pruebo con Hinrichs primero que ya los conozco y se usarlos)\n",
    "permutations = {2: (0, 1),\n",
    "                3: (0, 1, 2),\n",
    "                4: (0, 1, 3, 2),\n",
    "                5: (0, 2, 4, 1, 3),\n",
    "                6: (0, 2, 4, 1, 5, 3),\n",
    "                7: (0, 2, 4, 6, 1, 3, 5),\n",
    "                8: (0, 3, 6, 1, 4, 7, 2, 5),\n",
    "                9: (0, 2, 6, 3, 8, 5, 1, 7, 4),\n",
    "                10: (0, 3, 7, 1, 4, 9, 6, 2, 8, 5),\n",
    "                11: (0, 3, 8, 1, 6, 10, 4, 7, 2, 9, 5),\n",
    "                12: (0, 5, 10, 3, 8, 1, 6, 11, 4, 9, 2, 7),\n",
    "                13: (0, 5, 10, 2, 7, 12, 4, 9, 1, 6, 11, 3, 8),\n",
    "                14: (0, 5, 10, 2, 8, 13, 4, 11, 6, 1, 9, 3, 12, 7),\n",
    "                15: (0, 4, 9, 13, 6, 1, 11, 3, 8, 14, 5, 10, 2, 12, 7),\n",
    "                16: (0, 3, 11, 5, 14, 9, 1, 7, 12, 4, 15, 10, 2, 6, 13, 8),\n",
    "                }\n",
    "\n",
    "hinrichs = dict()\n",
    "for i in range(2, 17):\n",
    "    temp = []\n",
    "    for j, k in zip(range(i), permutations[i]):\n",
    "        temp.append((j/i, k/i))\n",
    "    hinrichs[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:13:56.623599Z",
     "iopub.status.busy": "2024-06-18T20:13:56.623599Z",
     "iopub.status.idle": "2024-06-18T20:13:56.631965Z",
     "shell.execute_reply": "2024-06-18T20:13:56.631965Z",
     "shell.execute_reply.started": "2024-06-18T20:13:56.623599Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [(0.0, 0.0), (0.5, 0.5)],\n",
       " 3: [(0.0, 0.0),\n",
       "  (0.3333333333333333, 0.3333333333333333),\n",
       "  (0.6666666666666666, 0.6666666666666666)],\n",
       " 4: [(0.0, 0.0), (0.25, 0.25), (0.5, 0.75), (0.75, 0.5)],\n",
       " 5: [(0.0, 0.0), (0.2, 0.4), (0.4, 0.8), (0.6, 0.2), (0.8, 0.6)],\n",
       " 6: [(0.0, 0.0),\n",
       "  (0.16666666666666666, 0.3333333333333333),\n",
       "  (0.3333333333333333, 0.6666666666666666),\n",
       "  (0.5, 0.16666666666666666),\n",
       "  (0.6666666666666666, 0.8333333333333334),\n",
       "  (0.8333333333333334, 0.5)],\n",
       " 7: [(0.0, 0.0),\n",
       "  (0.14285714285714285, 0.2857142857142857),\n",
       "  (0.2857142857142857, 0.5714285714285714),\n",
       "  (0.42857142857142855, 0.8571428571428571),\n",
       "  (0.5714285714285714, 0.14285714285714285),\n",
       "  (0.7142857142857143, 0.42857142857142855),\n",
       "  (0.8571428571428571, 0.7142857142857143)],\n",
       " 8: [(0.0, 0.0),\n",
       "  (0.125, 0.375),\n",
       "  (0.25, 0.75),\n",
       "  (0.375, 0.125),\n",
       "  (0.5, 0.5),\n",
       "  (0.625, 0.875),\n",
       "  (0.75, 0.25),\n",
       "  (0.875, 0.625)],\n",
       " 9: [(0.0, 0.0),\n",
       "  (0.1111111111111111, 0.2222222222222222),\n",
       "  (0.2222222222222222, 0.6666666666666666),\n",
       "  (0.3333333333333333, 0.3333333333333333),\n",
       "  (0.4444444444444444, 0.8888888888888888),\n",
       "  (0.5555555555555556, 0.5555555555555556),\n",
       "  (0.6666666666666666, 0.1111111111111111),\n",
       "  (0.7777777777777778, 0.7777777777777778),\n",
       "  (0.8888888888888888, 0.4444444444444444)],\n",
       " 10: [(0.0, 0.0),\n",
       "  (0.1, 0.3),\n",
       "  (0.2, 0.7),\n",
       "  (0.3, 0.1),\n",
       "  (0.4, 0.4),\n",
       "  (0.5, 0.9),\n",
       "  (0.6, 0.6),\n",
       "  (0.7, 0.2),\n",
       "  (0.8, 0.8),\n",
       "  (0.9, 0.5)],\n",
       " 11: [(0.0, 0.0),\n",
       "  (0.09090909090909091, 0.2727272727272727),\n",
       "  (0.18181818181818182, 0.7272727272727273),\n",
       "  (0.2727272727272727, 0.09090909090909091),\n",
       "  (0.36363636363636365, 0.5454545454545454),\n",
       "  (0.45454545454545453, 0.9090909090909091),\n",
       "  (0.5454545454545454, 0.36363636363636365),\n",
       "  (0.6363636363636364, 0.6363636363636364),\n",
       "  (0.7272727272727273, 0.18181818181818182),\n",
       "  (0.8181818181818182, 0.8181818181818182),\n",
       "  (0.9090909090909091, 0.45454545454545453)],\n",
       " 12: [(0.0, 0.0),\n",
       "  (0.08333333333333333, 0.4166666666666667),\n",
       "  (0.16666666666666666, 0.8333333333333334),\n",
       "  (0.25, 0.25),\n",
       "  (0.3333333333333333, 0.6666666666666666),\n",
       "  (0.4166666666666667, 0.08333333333333333),\n",
       "  (0.5, 0.5),\n",
       "  (0.5833333333333334, 0.9166666666666666),\n",
       "  (0.6666666666666666, 0.3333333333333333),\n",
       "  (0.75, 0.75),\n",
       "  (0.8333333333333334, 0.16666666666666666),\n",
       "  (0.9166666666666666, 0.5833333333333334)],\n",
       " 13: [(0.0, 0.0),\n",
       "  (0.07692307692307693, 0.38461538461538464),\n",
       "  (0.15384615384615385, 0.7692307692307693),\n",
       "  (0.23076923076923078, 0.15384615384615385),\n",
       "  (0.3076923076923077, 0.5384615384615384),\n",
       "  (0.38461538461538464, 0.9230769230769231),\n",
       "  (0.46153846153846156, 0.3076923076923077),\n",
       "  (0.5384615384615384, 0.6923076923076923),\n",
       "  (0.6153846153846154, 0.07692307692307693),\n",
       "  (0.6923076923076923, 0.46153846153846156),\n",
       "  (0.7692307692307693, 0.8461538461538461),\n",
       "  (0.8461538461538461, 0.23076923076923078),\n",
       "  (0.9230769230769231, 0.6153846153846154)],\n",
       " 14: [(0.0, 0.0),\n",
       "  (0.07142857142857142, 0.35714285714285715),\n",
       "  (0.14285714285714285, 0.7142857142857143),\n",
       "  (0.21428571428571427, 0.14285714285714285),\n",
       "  (0.2857142857142857, 0.5714285714285714),\n",
       "  (0.35714285714285715, 0.9285714285714286),\n",
       "  (0.42857142857142855, 0.2857142857142857),\n",
       "  (0.5, 0.7857142857142857),\n",
       "  (0.5714285714285714, 0.42857142857142855),\n",
       "  (0.6428571428571429, 0.07142857142857142),\n",
       "  (0.7142857142857143, 0.6428571428571429),\n",
       "  (0.7857142857142857, 0.21428571428571427),\n",
       "  (0.8571428571428571, 0.8571428571428571),\n",
       "  (0.9285714285714286, 0.5)],\n",
       " 15: [(0.0, 0.0),\n",
       "  (0.06666666666666667, 0.26666666666666666),\n",
       "  (0.13333333333333333, 0.6),\n",
       "  (0.2, 0.8666666666666667),\n",
       "  (0.26666666666666666, 0.4),\n",
       "  (0.3333333333333333, 0.06666666666666667),\n",
       "  (0.4, 0.7333333333333333),\n",
       "  (0.4666666666666667, 0.2),\n",
       "  (0.5333333333333333, 0.5333333333333333),\n",
       "  (0.6, 0.9333333333333333),\n",
       "  (0.6666666666666666, 0.3333333333333333),\n",
       "  (0.7333333333333333, 0.6666666666666666),\n",
       "  (0.8, 0.13333333333333333),\n",
       "  (0.8666666666666667, 0.8),\n",
       "  (0.9333333333333333, 0.4666666666666667)],\n",
       " 16: [(0.0, 0.0),\n",
       "  (0.0625, 0.1875),\n",
       "  (0.125, 0.6875),\n",
       "  (0.1875, 0.3125),\n",
       "  (0.25, 0.875),\n",
       "  (0.3125, 0.5625),\n",
       "  (0.375, 0.0625),\n",
       "  (0.4375, 0.4375),\n",
       "  (0.5, 0.75),\n",
       "  (0.5625, 0.25),\n",
       "  (0.625, 0.9375),\n",
       "  (0.6875, 0.625),\n",
       "  (0.75, 0.125),\n",
       "  (0.8125, 0.375),\n",
       "  (0.875, 0.8125),\n",
       "  (0.9375, 0.5)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinrichs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3798285359.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    N ~ AreaTotal/AreaQuadrat * Media(PersonasContadasEnCadaPunto)\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "N ~ AreaTotal/AreaQuadrat * Media(PersonasContadasEnCadaPunto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on ShanghaiTech A (with GT labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-19T19:00:37.342048Z",
     "iopub.status.busy": "2024-06-19T19:00:37.342048Z",
     "iopub.status.idle": "2024-06-19T19:09:50.666926Z",
     "shell.execute_reply": "2024-06-19T19:09:50.666926Z",
     "shell.execute_reply.started": "2024-06-19T19:00:37.342048Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "16\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "17\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "104\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "122\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "133\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "138\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "139\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "140\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "141\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "149\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "155\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "156\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "163\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "173\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "174\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "177\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "184\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "187\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "190\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "194\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "196\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "197\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "198\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "200\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "201\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "205\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "206\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "215\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "219\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n",
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n"
     ]
    }
   ],
   "source": [
    "##########################################prueba\n",
    "for itera in range(224):\n",
    "    window_size = itera\n",
    "    stride = itera\n",
    "    try:\n",
    "        dataset_name = \"sha\" #select dataset name\n",
    "        split = \"val\"\n",
    "        \n",
    "        if truncation is None:  # regression, no truncation.\n",
    "            bins, anchor_points = None, None\n",
    "        else:\n",
    "            with open(os.path.join(parent_dir, \"configs\", f\"reduction_{reduction}.json\"), \"r\") as f:\n",
    "                config = json.load(f)[str(truncation)][dataset_name]\n",
    "            bins = config[\"bins\"][granularity]\n",
    "            anchor_points = config[\"anchor_points\"][granularity][\"average\"] if anchor_points == \"average\" else config[\"anchor_points\"][granularity][\"middle\"]\n",
    "            bins = [(float(b[0]), float(b[1])) for b in bins]\n",
    "            anchor_points = [float(p) for p in anchor_points]\n",
    "        \n",
    "        model = get_model(\n",
    "            backbone=model_name,\n",
    "            input_size=input_size, \n",
    "            reduction=reduction,\n",
    "            bins=bins,\n",
    "            anchor_points=anchor_points,\n",
    "            # CLIP parameters\n",
    "            prompt_type=prompt_type,\n",
    "            num_vpt=num_vpt,\n",
    "            vpt_drop=vpt_drop,\n",
    "            deep_vpt=deep_vpt\n",
    "        )\n",
    "        \n",
    "        #Change ckpt_dir_name to get the weights you want\n",
    "        #ckpt_dir_name = f\"{model_name}_{prompt_type}_\" if \"clip\" in model_name else f\"{model_name}_\"\n",
    "        #ckpt_dir_name += f\"{input_size}_{reduction}_{truncation}_{granularity}_\"\n",
    "        #ckpt_dir_name += f\"{weight_count_loss}_{count_loss}\"\n",
    "        ckpt_dir_name = 'ShanghaiTech_A_CLIP_EBC_ViT_B_16_Word'\n",
    "        \n",
    "        ckpt_path = os.path.join(\n",
    "            parent_dir,\n",
    "            \"checkpoints\",\n",
    "            ckpt_dir_name,\n",
    "            \"best_mae.pth\"  # select the weight file that you want to test\n",
    "        )\n",
    "        ckpt = torch.load(ckpt_path, map_location=device)\n",
    "        model.load_state_dict(ckpt)\n",
    "        model = model.to(device)\n",
    "\n",
    "        dataset = datasets.Crowd(dataset=dataset_name, split=split, sigma=8, return_filename=True)\n",
    "        dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, collate_fn=datasets.collate_fn)\n",
    "        data_iter = iter(dataloader)\n",
    "\n",
    "        img_id = None\n",
    "        model.eval() #No estoy seguro de si deberia meter esto en el bucle\n",
    "        \n",
    "        h16_sha_df_eval = pd.DataFrame() #Notación: h2 == hinrichs con n=2\n",
    "        imagenes_recorridas = 0\n",
    "        while True:\n",
    "            try:\n",
    "                image, points, density, image_path = next(data_iter)\n",
    "                imagenes_recorridas += 1\n",
    "            except: #Sólo debería entrar aquí si llega al final de las iteraciones\n",
    "                print('Imagenes en el dataset: ', dataset.__len__())\n",
    "                print('Imagenes recorridas: ', imagenes_recorridas)\n",
    "                break\n",
    "            \n",
    "            original_image = image\n",
    "            image_height, image_width = image.shape[-2:]\n",
    "            #image = image.to(device)\n",
    "            image_name = os.path.basename(image_path[0])\n",
    "        \n",
    "            #Recortar la imagen antes de evaluar el modelo (NO SE SI EL STRIDE IMPORTA O NO POR LA SLIDING WINDOW)\n",
    "            N = 16 #NUMBER OF POINTS TO CONSIDER IN THE OPTIMAL POINT SET (tendre que hacer un bucle sobre range(N) para predecir modelo en cada recorte)\n",
    "            pointset = hinrichs[N]\n",
    "            cuentas = np.array([])\n",
    "            \n",
    "            for i in range(N): #Aqui deberia hacer bucle para cada punto...\n",
    "                point = pointset[i]\n",
    "                left = math.floor(point[0]*image_width)\n",
    "                right = math.floor((point[0]+1/N)*image_width)\n",
    "                bottom = math.floor(point[1]*image_height)\n",
    "                top = math.floor((point[1]+1/N)*image_height)\n",
    "                #Recorto la imagen tq la \"\"\"\"\"\"\"\"esquina inferior izquierda\"\"\"\"\"\"\"\"\"\" del recorte es el punto óptimo del pointset\n",
    "                image = original_image[:,:,bottom:top,left:right] #OBS: Tamaño del recorte = máximo tq el recorte no se sobrepone a los demás ni se sale del tamaño\n",
    "                new_image_height, new_image_width = image.shape[-2:]\n",
    "                image = image.to(device)\n",
    "            \n",
    "                with torch.no_grad():\n",
    "                    if stride is not None:  # Sliding window prediction.\n",
    "                        pred_density = sliding_window_predict(model, image, window_size, stride)\n",
    "                    else:\n",
    "                        pred_density = model(image)\n",
    "                    pred_count = pred_density.sum().item()\n",
    "                    #resized_pred_density = resize_density_map(pred_density, (new_image_height, new_image_width)).cpu()\n",
    "                print(itera)\n",
    "                break\n",
    "                #density = density.squeeze().numpy()\n",
    "                #resized_pred_density = resized_pred_density.squeeze().numpy()\n",
    "                #points = points[0].numpy() #EN SHA Y SHB POINTS PARECE SER YA UN ARRAY, EN QNRF DEBO DESCOMENTAR ESTA LINEA Y COMENTAR LA SIGUIENTE\n",
    "                #points = points[0]\n",
    "                cuentas = np.append(cuentas, pred_count)\n",
    "            break\n",
    "            \n",
    "            h16_sha_df_eval.loc[image_name,'Pred_Count'] = N**2 * cuentas.mean() #((image_height*image_width) / ((image_height/N)*(image_width/N))) * cuentas.mean()\n",
    "            h16_sha_df_eval.loc[image_name,'Pred_Count_Variance'] = np.var(N**2 * cuentas)\n",
    "            #h16_sha_df_eval.loc[image_name,'GT Count'] = len(points)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:14:11.655628Z",
     "iopub.status.busy": "2024-06-19T19:14:11.655628Z",
     "iopub.status.idle": "2024-06-19T19:14:14.303665Z",
     "shell.execute_reply": "2024-06-19T19:14:14.303665Z",
     "shell.execute_reply.started": "2024-06-19T19:14:11.655628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"sha\" #select dataset name\n",
    "split = \"val\"\n",
    "\n",
    "if truncation is None:  # regression, no truncation.\n",
    "    bins, anchor_points = None, None\n",
    "else:\n",
    "    with open(os.path.join(parent_dir, \"configs\", f\"reduction_{reduction}.json\"), \"r\") as f:\n",
    "        config = json.load(f)[str(truncation)][dataset_name]\n",
    "    bins = config[\"bins\"][granularity]\n",
    "    anchor_points = config[\"anchor_points\"][granularity][\"average\"] if anchor_points == \"average\" else config[\"anchor_points\"][granularity][\"middle\"]\n",
    "    bins = [(float(b[0]), float(b[1])) for b in bins]\n",
    "    anchor_points = [float(p) for p in anchor_points]\n",
    "\n",
    "model = get_model(\n",
    "    backbone=model_name,\n",
    "    input_size=input_size, \n",
    "    reduction=reduction,\n",
    "    bins=bins,\n",
    "    anchor_points=anchor_points,\n",
    "    # CLIP parameters\n",
    "    prompt_type=prompt_type,\n",
    "    num_vpt=num_vpt,\n",
    "    vpt_drop=vpt_drop,\n",
    "    deep_vpt=deep_vpt\n",
    ")\n",
    "\n",
    "#Change ckpt_dir_name to get the weights you want\n",
    "#ckpt_dir_name = f\"{model_name}_{prompt_type}_\" if \"clip\" in model_name else f\"{model_name}_\"\n",
    "#ckpt_dir_name += f\"{input_size}_{reduction}_{truncation}_{granularity}_\"\n",
    "#ckpt_dir_name += f\"{weight_count_loss}_{count_loss}\"\n",
    "ckpt_dir_name = 'ShanghaiTech_A_CLIP_EBC_ViT_B_16_Word'\n",
    "\n",
    "ckpt_path = os.path.join(\n",
    "    parent_dir,\n",
    "    \"checkpoints\",\n",
    "    ckpt_dir_name,\n",
    "    \"best_mae.pth\"  # select the weight file that you want to test\n",
    ")\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:14:14.305673Z",
     "iopub.status.busy": "2024-06-19T19:14:14.305673Z",
     "iopub.status.idle": "2024-06-19T19:14:14.320908Z",
     "shell.execute_reply": "2024-06-19T19:14:14.320908Z",
     "shell.execute_reply.started": "2024-06-19T19:14:14.305673Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.Crowd(dataset=dataset_name, split=split, sigma=8, return_filename=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, collate_fn=datasets.collate_fn)\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#CODIGO PARA COMPROBAR QUE next(data_iter) RECORRE TODAS LAS IMAGENES BIEN\n",
    "img_id = None #CODIGO PARA VER QUE EL RECORTE LE HAGO BIEN\n",
    "model.eval()\n",
    "aux=pd.Series()\n",
    "for i in range(182): #Hay 182 imagenes en sha, si pongo range(183) da error de StopIteration\n",
    "    image, points, density, image_path = next(data_iter) \n",
    "    aux[i] = (os.path.basename(image_path[0]))\n",
    "len(aux.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:14:14.320908Z",
     "iopub.status.busy": "2024-06-19T19:14:14.320908Z",
     "iopub.status.idle": "2024-06-19T19:31:29.505030Z",
     "shell.execute_reply": "2024-06-19T19:31:29.505030Z",
     "shell.execute_reply.started": "2024-06-19T19:14:14.320908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes en el dataset:  182\n",
      "Imagenes recorridas:  182\n"
     ]
    }
   ],
   "source": [
    "img_id = None\n",
    "model.eval() #No estoy seguro de si deberia meter esto en el bucle\n",
    "\n",
    "h16_sha_df_eval = pd.DataFrame() #Notación: h2 == hinrichs con n=2\n",
    "imagenes_recorridas = 0\n",
    "while True:\n",
    "    try:\n",
    "        image, points, density, image_path = next(data_iter)\n",
    "        imagenes_recorridas += 1\n",
    "    except: #Sólo debería entrar aquí si llega al final de las iteraciones\n",
    "        print('Imagenes en el dataset: ', dataset.__len__())\n",
    "        print('Imagenes recorridas: ', imagenes_recorridas)\n",
    "        break\n",
    "    \n",
    "    original_image = image\n",
    "    image_height, image_width = image.shape[-2:]\n",
    "    #image = image.to(device)\n",
    "    image_name = os.path.basename(image_path[0])\n",
    "\n",
    "    #Recortar la imagen antes de evaluar el modelo (NO SE SI EL STRIDE IMPORTA O NO POR LA SLIDING WINDOW)\n",
    "    N = 16 #NUMBER OF POINTS TO CONSIDER IN THE OPTIMAL POINT SET (tendre que hacer un bucle sobre range(N) para predecir modelo en cada recorte)\n",
    "    pointset = hinrichs[N]\n",
    "    cuentas = np.array([])\n",
    "    \n",
    "    for i in range(N): #Aqui deberia hacer bucle para cada punto...\n",
    "        point = pointset[i]\n",
    "        left = math.floor(point[0]*image_width)\n",
    "        right = math.floor((point[0]+1/N)*image_width)\n",
    "        bottom = math.floor(point[1]*image_height)\n",
    "        top = math.floor((point[1]+1/N)*image_height)\n",
    "        #Recorto la imagen tq la \"\"\"\"\"\"\"\"esquina inferior izquierda\"\"\"\"\"\"\"\"\"\" del recorte es el punto óptimo del pointset\n",
    "        image = original_image[:,:,bottom:top,left:right] #OBS: Tamaño del recorte = máximo tq el recorte no se sobrepone a los demás ni se sale del tamaño\n",
    "        new_image_height, new_image_width = image.shape[-2:]\n",
    "        image = image.to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if stride is not None:  # Sliding window prediction.\n",
    "                pred_density = sliding_window_predict(model, image, window_size, stride)\n",
    "            else:\n",
    "                pred_density = model(image)\n",
    "            pred_count = pred_density.sum().item()\n",
    "            #resized_pred_density = resize_density_map(pred_density, (new_image_height, new_image_width)).cpu()\n",
    "        \n",
    "        #density = density.squeeze().numpy()\n",
    "        #resized_pred_density = resized_pred_density.squeeze().numpy()\n",
    "        #points = points[0].numpy() #EN SHA Y SHB POINTS PARECE SER YA UN ARRAY, EN QNRF DEBO DESCOMENTAR ESTA LINEA Y COMENTAR LA SIGUIENTE\n",
    "        #points = points[0]\n",
    "        cuentas = np.append(cuentas, pred_count)\n",
    "\n",
    "    \n",
    "    h16_sha_df_eval.loc[image_name,'Pred_Count'] = N**2 * cuentas.mean() #((image_height*image_width) / ((image_height/N)*(image_width/N))) * cuentas.mean()\n",
    "    h16_sha_df_eval.loc[image_name,'Pred_Count_Variance'] = np.var(N**2 * cuentas)\n",
    "    #h16_sha_df_eval.loc[image_name,'GT Count'] = len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El código de arriba tarda: 17 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo los datos obtenidos para no tener que correr el bucle de nuevo si reinicio jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:34:51.671015Z",
     "iopub.status.busy": "2024-06-19T19:34:51.669779Z",
     "iopub.status.idle": "2024-06-19T19:34:51.698895Z",
     "shell.execute_reply": "2024-06-19T19:34:51.698895Z",
     "shell.execute_reply.started": "2024-06-19T19:34:51.671015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'h16_sha_df_eval' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store h16_sha_df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargo los datos obtenidos para no tener que correr el bucle de nuevo si reinicio jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r h16_sha_df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:34:55.091636Z",
     "iopub.status.busy": "2024-06-19T19:34:55.091636Z",
     "iopub.status.idle": "2024-06-19T19:34:55.122560Z",
     "shell.execute_reply": "2024-06-19T19:34:55.122560Z",
     "shell.execute_reply.started": "2024-06-19T19:34:55.091636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_Count</th>\n",
       "      <th>Pred_Count_Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002.jpg</th>\n",
       "      <td>5140.758420</td>\n",
       "      <td>1.681617e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>056.jpg</th>\n",
       "      <td>1359.179073</td>\n",
       "      <td>1.312189e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025.jpg</th>\n",
       "      <td>500.798306</td>\n",
       "      <td>4.165729e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171.jpg</th>\n",
       "      <td>1954.810347</td>\n",
       "      <td>3.710589e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149.jpg</th>\n",
       "      <td>58.363895</td>\n",
       "      <td>4.486441e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123.jpg</th>\n",
       "      <td>1357.972394</td>\n",
       "      <td>1.206371e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>069.jpg</th>\n",
       "      <td>1133.452609</td>\n",
       "      <td>5.672474e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>045.jpg</th>\n",
       "      <td>6.965912</td>\n",
       "      <td>9.607255e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>052.jpg</th>\n",
       "      <td>390.295158</td>\n",
       "      <td>1.900104e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160.jpg</th>\n",
       "      <td>413.391121</td>\n",
       "      <td>1.301641e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred_Count  Pred_Count_Variance\n",
       "002.jpg  5140.758420         1.681617e+07\n",
       "056.jpg  1359.179073         1.312189e+06\n",
       "025.jpg   500.798306         4.165729e+05\n",
       "171.jpg  1954.810347         3.710589e+06\n",
       "149.jpg    58.363895         4.486441e+03\n",
       "...              ...                  ...\n",
       "123.jpg  1357.972394         1.206371e+06\n",
       "069.jpg  1133.452609         5.672474e+05\n",
       "045.jpg     6.965912         9.607255e+01\n",
       "052.jpg   390.295158         1.900104e+05\n",
       "160.jpg   413.391121         1.301641e+05\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h16_sha_df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on ShanghaiTech B (with GT labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:35:25.021622Z",
     "iopub.status.busy": "2024-06-19T19:35:25.021622Z",
     "iopub.status.idle": "2024-06-19T19:35:27.522282Z",
     "shell.execute_reply": "2024-06-19T19:35:27.522282Z",
     "shell.execute_reply.started": "2024-06-19T19:35:25.021622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"shb\" #select dataset name\n",
    "split = \"val\"\n",
    "\n",
    "if truncation is None:  # regression, no truncation.\n",
    "    bins, anchor_points = None, None\n",
    "else:\n",
    "    with open(os.path.join(parent_dir, \"configs\", f\"reduction_{reduction}.json\"), \"r\") as f:\n",
    "        config = json.load(f)[str(truncation)][dataset_name]\n",
    "    bins = config[\"bins\"][granularity]\n",
    "    anchor_points = config[\"anchor_points\"][granularity][\"average\"] if anchor_points == \"average\" else config[\"anchor_points\"][granularity][\"middle\"]\n",
    "    bins = [(float(b[0]), float(b[1])) for b in bins]\n",
    "    anchor_points = [float(p) for p in anchor_points]\n",
    "\n",
    "model = get_model(\n",
    "    backbone=model_name,\n",
    "    input_size=input_size, \n",
    "    reduction=reduction,\n",
    "    bins=bins,\n",
    "    anchor_points=anchor_points,\n",
    "    # CLIP parameters\n",
    "    prompt_type=prompt_type,\n",
    "    num_vpt=num_vpt,\n",
    "    vpt_drop=vpt_drop,\n",
    "    deep_vpt=deep_vpt\n",
    ")\n",
    "\n",
    "#Change ckpt_dir_name to get the weights you want\n",
    "#ckpt_dir_name = f\"{model_name}_{prompt_type}_\" if \"clip\" in model_name else f\"{model_name}_\"\n",
    "#ckpt_dir_name += f\"{input_size}_{reduction}_{truncation}_{granularity}_\"\n",
    "#ckpt_dir_name += f\"{weight_count_loss}_{count_loss}\"\n",
    "ckpt_dir_name = 'ShanghaiTech_B_CLIP_EBC_ViT_B_16_Word'\n",
    "\n",
    "ckpt_path = os.path.join(\n",
    "    parent_dir,\n",
    "    \"checkpoints\",\n",
    "    ckpt_dir_name,\n",
    "    \"best_mae.pth\"  # select the weight file that you want to test\n",
    ")\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:35:28.739884Z",
     "iopub.status.busy": "2024-06-19T19:35:28.739884Z",
     "iopub.status.idle": "2024-06-19T19:35:28.755208Z",
     "shell.execute_reply": "2024-06-19T19:35:28.755208Z",
     "shell.execute_reply.started": "2024-06-19T19:35:28.739884Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.Crowd(dataset=dataset_name, split=split, sigma=8, return_filename=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, collate_fn=datasets.collate_fn)\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T19:35:29.914092Z",
     "iopub.status.busy": "2024-06-19T19:35:29.914092Z",
     "iopub.status.idle": "2024-06-19T20:10:35.249539Z",
     "shell.execute_reply": "2024-06-19T20:10:35.249539Z",
     "shell.execute_reply.started": "2024-06-19T19:35:29.914092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes en el dataset:  316\n",
      "Imagenes recorridas:  316\n"
     ]
    }
   ],
   "source": [
    "img_id = None\n",
    "model.eval() #No estoy seguro de si deberia meter esto en el bucle\n",
    "\n",
    "h16_shb_df_eval = pd.DataFrame()\n",
    "imagenes_recorridas = 0\n",
    "while True:\n",
    "    try:\n",
    "        image, points, density, image_path = next(data_iter)\n",
    "        imagenes_recorridas += 1\n",
    "    except: #Sólo debería entrar aquí si llega al final de las iteraciones\n",
    "        print('Imagenes en el dataset: ', dataset.__len__())\n",
    "        print('Imagenes recorridas: ', imagenes_recorridas)\n",
    "        break\n",
    "    \n",
    "    original_image = image\n",
    "    image_height, image_width = image.shape[-2:]\n",
    "    #image = image.to(device)\n",
    "    image_name = os.path.basename(image_path[0])\n",
    "\n",
    "    #Recortar la imagen antes de evaluar el modelo (NO SE SI EL STRIDE IMPORTA O NO POR LA SLIDING WINDOW)\n",
    "    N = 16 #NUMBER OF POINTS TO CONSIDER IN THE OPTIMAL POINT SET (tendre que hacer un bucle sobre range(N) para predecir modelo en cada recorte)\n",
    "    pointset = hinrichs[N]\n",
    "    cuentas = np.array([])\n",
    "    \n",
    "    for i in range(N): #Aqui deberia hacer bucle para cada punto...\n",
    "        point = pointset[i]\n",
    "        left = math.floor(point[0]*image_width)\n",
    "        right = math.floor((point[0]+1/N)*image_width)\n",
    "        bottom = math.floor(point[1]*image_height)\n",
    "        top = math.floor((point[1]+1/N)*image_height)\n",
    "        #Recorto la imagen tq la \"\"\"\"\"\"\"\"esquina inferior izquierda\"\"\"\"\"\"\"\"\"\" del recorte es el punto óptimo del pointset\n",
    "        image = original_image[:,:,bottom:top,left:right] #OBS: Tamaño del recorte = máximo tq el recorte no se sobrepone a los demás ni se sale del tamaño\n",
    "        new_image_height, new_image_width = image.shape[-2:]\n",
    "        image = image.to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if stride is not None:  # Sliding window prediction.\n",
    "                pred_density = sliding_window_predict(model, image, window_size, stride)\n",
    "            else:\n",
    "                pred_density = model(image)\n",
    "            pred_count = pred_density.sum().item()\n",
    "            #resized_pred_density = resize_density_map(pred_density, (new_image_height, new_image_width)).cpu()\n",
    "        \n",
    "        #density = density.squeeze().numpy()\n",
    "        #resized_pred_density = resized_pred_density.squeeze().numpy()\n",
    "        #points = points[0].numpy() #EN SHA Y SHB POINTS PARECE SER YA UN ARRAY, EN QNRF DEBO DESCOMENTAR ESTA LINEA Y COMENTAR LA SIGUIENTE\n",
    "        #points = points[0]\n",
    "        cuentas = np.append(cuentas, pred_count)\n",
    "\n",
    "    \n",
    "    h16_shb_df_eval.loc[image_name,'Pred_Count'] = N**2 * cuentas.mean() #((image_height*image_width) / ((image_height/N)*(image_width/N))) * cuentas.mean()\n",
    "    h16_shb_df_eval.loc[image_name,'Pred_Count_Variance'] = np.var(N**2 * cuentas)\n",
    "    #h16_shb_df_eval.loc[image_name,'GT Count'] = len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El código de arriba tarda: 35 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T20:10:35.252619Z",
     "iopub.status.busy": "2024-06-19T20:10:35.251622Z",
     "iopub.status.idle": "2024-06-19T20:10:35.257838Z",
     "shell.execute_reply": "2024-06-19T20:10:35.257838Z",
     "shell.execute_reply.started": "2024-06-19T20:10:35.251622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'h16_shb_df_eval' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store h16_shb_df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r h16_shb_df_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T20:10:35.259834Z",
     "iopub.status.busy": "2024-06-19T20:10:35.258837Z",
     "iopub.status.idle": "2024-06-19T20:10:35.275463Z",
     "shell.execute_reply": "2024-06-19T20:10:35.274735Z",
     "shell.execute_reply.started": "2024-06-19T20:10:35.258837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_Count</th>\n",
       "      <th>Pred_Count_Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297.jpg</th>\n",
       "      <td>135.625973</td>\n",
       "      <td>33639.839615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248.jpg</th>\n",
       "      <td>305.819116</td>\n",
       "      <td>229917.632282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244.jpg</th>\n",
       "      <td>222.180472</td>\n",
       "      <td>115513.136885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199.jpg</th>\n",
       "      <td>363.434854</td>\n",
       "      <td>167811.195605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167.jpg</th>\n",
       "      <td>123.448751</td>\n",
       "      <td>41968.400802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>074.jpg</th>\n",
       "      <td>280.636463</td>\n",
       "      <td>161242.651720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133.jpg</th>\n",
       "      <td>283.990090</td>\n",
       "      <td>243407.517244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252.jpg</th>\n",
       "      <td>282.735517</td>\n",
       "      <td>206403.344569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>039.jpg</th>\n",
       "      <td>263.313352</td>\n",
       "      <td>122041.705115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>016.jpg</th>\n",
       "      <td>131.145187</td>\n",
       "      <td>86027.072891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred_Count  Pred_Count_Variance\n",
       "297.jpg  135.625973         33639.839615\n",
       "248.jpg  305.819116        229917.632282\n",
       "244.jpg  222.180472        115513.136885\n",
       "199.jpg  363.434854        167811.195605\n",
       "167.jpg  123.448751         41968.400802\n",
       "...             ...                  ...\n",
       "074.jpg  280.636463        161242.651720\n",
       "133.jpg  283.990090        243407.517244\n",
       "252.jpg  282.735517        206403.344569\n",
       "039.jpg  263.313352        122041.705115\n",
       "016.jpg  131.145187         86027.072891\n",
       "\n",
       "[316 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h16_shb_df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on UCF-QNRF (with GT labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T20:10:35.275463Z",
     "iopub.status.busy": "2024-06-19T20:10:35.275463Z",
     "iopub.status.idle": "2024-06-19T20:10:38.255856Z",
     "shell.execute_reply": "2024-06-19T20:10:38.255856Z",
     "shell.execute_reply.started": "2024-06-19T20:10:35.275463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"qnrf\" #select dataset name\n",
    "split = \"val\"\n",
    "\n",
    "if truncation is None:  # regression, no truncation.\n",
    "    bins, anchor_points = None, None\n",
    "else:\n",
    "    with open(os.path.join(parent_dir, \"configs\", f\"reduction_{reduction}.json\"), \"r\") as f:\n",
    "        config = json.load(f)[str(truncation)][dataset_name]\n",
    "    bins = config[\"bins\"][granularity]\n",
    "    anchor_points = config[\"anchor_points\"][granularity][\"average\"] if anchor_points == \"average\" else config[\"anchor_points\"][granularity][\"middle\"]\n",
    "    bins = [(float(b[0]), float(b[1])) for b in bins]\n",
    "    anchor_points = [float(p) for p in anchor_points]\n",
    "\n",
    "model = get_model(\n",
    "    backbone=model_name,\n",
    "    input_size=input_size, \n",
    "    reduction=reduction,\n",
    "    bins=bins,\n",
    "    anchor_points=anchor_points,\n",
    "    # CLIP parameters\n",
    "    prompt_type=prompt_type,\n",
    "    num_vpt=num_vpt,\n",
    "    vpt_drop=vpt_drop,\n",
    "    deep_vpt=deep_vpt\n",
    ")\n",
    "\n",
    "#Change ckpt_dir_name to get the weights you want\n",
    "#ckpt_dir_name = f\"{model_name}_{prompt_type}_\" if \"clip\" in model_name else f\"{model_name}_\"\n",
    "#ckpt_dir_name += f\"{input_size}_{reduction}_{truncation}_{granularity}_\"\n",
    "#ckpt_dir_name += f\"{weight_count_loss}_{count_loss}\"\n",
    "ckpt_dir_name = 'UCF_QNRF_CLIP_EBC_ViT_B_16_Word'\n",
    "\n",
    "ckpt_path = os.path.join(\n",
    "    parent_dir,\n",
    "    \"checkpoints\",\n",
    "    ckpt_dir_name,\n",
    "    \"best_mae.pth\"  # select the weight file that you want to test\n",
    ")\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T20:10:38.255856Z",
     "iopub.status.busy": "2024-06-19T20:10:38.255856Z",
     "iopub.status.idle": "2024-06-19T20:10:38.283898Z",
     "shell.execute_reply": "2024-06-19T20:10:38.283898Z",
     "shell.execute_reply.started": "2024-06-19T20:10:38.255856Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.Crowd(dataset=dataset_name, split=split, sigma=8, return_filename=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, collate_fn=datasets.collate_fn)\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T20:10:38.283898Z",
     "iopub.status.busy": "2024-06-19T20:10:38.283898Z",
     "iopub.status.idle": "2024-06-19T22:05:37.244722Z",
     "shell.execute_reply": "2024-06-19T22:05:37.244722Z",
     "shell.execute_reply.started": "2024-06-19T20:10:38.283898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes en el dataset:  334\n",
      "Imagenes recorridas:  334\n"
     ]
    }
   ],
   "source": [
    "img_id = None\n",
    "model.eval() #No estoy seguro de si deberia meter esto en el bucle\n",
    "\n",
    "h16_qnrf_df_eval = pd.DataFrame()\n",
    "imagenes_recorridas = 0\n",
    "while True:\n",
    "    try:\n",
    "        image, points, density, image_path = next(data_iter)\n",
    "        imagenes_recorridas += 1\n",
    "    except: #Sólo debería entrar aquí si llega al final de las iteraciones\n",
    "        print('Imagenes en el dataset: ', dataset.__len__())\n",
    "        print('Imagenes recorridas: ', imagenes_recorridas)\n",
    "        break\n",
    "    \n",
    "    original_image = image\n",
    "    image_height, image_width = image.shape[-2:]\n",
    "    #image = image.to(device)\n",
    "    image_name = os.path.basename(image_path[0])\n",
    "\n",
    "    #Recortar la imagen antes de evaluar el modelo (NO SE SI EL STRIDE IMPORTA O NO POR LA SLIDING WINDOW)\n",
    "    N = 16 #NUMBER OF POINTS TO CONSIDER IN THE OPTIMAL POINT SET (tendre que hacer un bucle sobre range(N) para predecir modelo en cada recorte)\n",
    "    pointset = hinrichs[N]\n",
    "    cuentas = np.array([])\n",
    "    \n",
    "    for i in range(N): #Aqui deberia hacer bucle para cada punto...\n",
    "        point = pointset[i]\n",
    "        left = math.floor(point[0]*image_width)\n",
    "        right = math.floor((point[0]+1/N)*image_width)\n",
    "        bottom = math.floor(point[1]*image_height)\n",
    "        top = math.floor((point[1]+1/N)*image_height)\n",
    "        #Recorto la imagen tq la \"\"\"\"\"\"\"\"esquina inferior izquierda\"\"\"\"\"\"\"\"\"\" del recorte es el punto óptimo del pointset\n",
    "        image = original_image[:,:,bottom:top,left:right] #OBS: Tamaño del recorte = máximo tq el recorte no se sobrepone a los demás ni se sale del tamaño\n",
    "        new_image_height, new_image_width = image.shape[-2:]\n",
    "        image = image.to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if stride is not None:  # Sliding window prediction.\n",
    "                pred_density = sliding_window_predict(model, image, window_size, stride)\n",
    "            else:\n",
    "                pred_density = model(image)\n",
    "            pred_count = pred_density.sum().item()\n",
    "            #resized_pred_density = resize_density_map(pred_density, (new_image_height, new_image_width)).cpu()\n",
    "        \n",
    "        #density = density.squeeze().numpy()\n",
    "        #resized_pred_density = resized_pred_density.squeeze().numpy()\n",
    "        #points = points[0]\n",
    "        cuentas = np.append(cuentas, pred_count)\n",
    "\n",
    "    \n",
    "    h16_qnrf_df_eval.loc[image_name,'Pred_Count'] = N**2 * cuentas.mean() #((image_height*image_width) / ((image_height/N)*(image_width/N))) * cuentas.mean()\n",
    "    h16_qnrf_df_eval.loc[image_name,'Pred_Count_Variance'] = np.var(N**2 * cuentas)\n",
    "    #h16_qnrf_df_eval.loc[image_name,'GT Count'] = len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El código de arriba tarda: 1h y 54 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T22:05:37.248010Z",
     "iopub.status.busy": "2024-06-19T22:05:37.247013Z",
     "iopub.status.idle": "2024-06-19T22:05:37.255028Z",
     "shell.execute_reply": "2024-06-19T22:05:37.254884Z",
     "shell.execute_reply.started": "2024-06-19T22:05:37.248010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'h16_qnrf_df_eval' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store h16_qnrf_df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r h16_qnrf_df_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T22:05:37.257064Z",
     "iopub.status.busy": "2024-06-19T22:05:37.257064Z",
     "iopub.status.idle": "2024-06-19T22:05:37.301710Z",
     "shell.execute_reply": "2024-06-19T22:05:37.301710Z",
     "shell.execute_reply.started": "2024-06-19T22:05:37.257064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_Count</th>\n",
       "      <th>Pred_Count_Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>085.jpg</th>\n",
       "      <td>6848.763651</td>\n",
       "      <td>1.368980e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008.jpg</th>\n",
       "      <td>2701.773753</td>\n",
       "      <td>6.765069e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226.jpg</th>\n",
       "      <td>6908.120884</td>\n",
       "      <td>2.928430e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215.jpg</th>\n",
       "      <td>3101.664412</td>\n",
       "      <td>1.736371e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117.jpg</th>\n",
       "      <td>8241.821045</td>\n",
       "      <td>8.125220e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089.jpg</th>\n",
       "      <td>6838.600346</td>\n",
       "      <td>4.705956e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>077.jpg</th>\n",
       "      <td>4552.097808</td>\n",
       "      <td>8.489470e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221.jpg</th>\n",
       "      <td>4059.151546</td>\n",
       "      <td>4.948262e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163.jpg</th>\n",
       "      <td>2184.002296</td>\n",
       "      <td>9.573856e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>048.jpg</th>\n",
       "      <td>5691.034775</td>\n",
       "      <td>1.909659e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred_Count  Pred_Count_Variance\n",
       "085.jpg  6848.763651         1.368980e+07\n",
       "008.jpg  2701.773753         6.765069e+06\n",
       "226.jpg  6908.120884         2.928430e+07\n",
       "215.jpg  3101.664412         1.736371e+07\n",
       "117.jpg  8241.821045         8.125220e+06\n",
       "...              ...                  ...\n",
       "089.jpg  6838.600346         4.705956e+07\n",
       "077.jpg  4552.097808         8.489470e+06\n",
       "221.jpg  4059.151546         4.948262e+06\n",
       "163.jpg  2184.002296         9.573856e+06\n",
       "048.jpg  5691.034775         1.909659e+07\n",
       "\n",
       "[334 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h16_qnrf_df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No ejecutar más código, tarda mucho y no merece la pena porque no tengo la cantidad de personas en cada imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on NWPU-Test (without GT labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: []\n",
      "Unexpected keys: ['proj']\n",
      "All keys matched successfully.\n",
      "Initialized model with text prompts: ['There is no person.', 'There is one person.', 'There are two people.', 'There are three people.', 'There are more than four people.']\n"
     ]
    }
   ],
   "source": [
    "if truncation is None:  # regression, no truncation.\n",
    "    bins, anchor_points = None, None\n",
    "else:\n",
    "    with open(os.path.join(parent_dir, \"configs\", f\"reduction_{reduction}.json\"), \"r\") as f:\n",
    "        config = json.load(f)[str(truncation)][\"nwpu\"]\n",
    "    bins = config[\"bins\"][granularity]\n",
    "    anchor_points = config[\"anchor_points\"][granularity][\"average\"] if anchor_points == \"average\" else config[\"anchor_points\"][granularity][\"middle\"]\n",
    "    bins = [(float(b[0]), float(b[1])) for b in bins]\n",
    "    anchor_points = [float(p) for p in anchor_points]\n",
    "\n",
    "\n",
    "model = get_model(\n",
    "    backbone=model_name,\n",
    "    input_size=input_size, \n",
    "    reduction=reduction,\n",
    "    bins=bins,\n",
    "    anchor_points=anchor_points,\n",
    "    # CLIP parameters\n",
    "    prompt_type=prompt_type,\n",
    "    num_vpt=num_vpt,\n",
    "    vpt_drop=vpt_drop,\n",
    "    deep_vpt=deep_vpt\n",
    ")\n",
    "\n",
    "\n",
    "#Change ckpt_dir_name to get the weights you want\n",
    "#ckpt_dir_name = f\"{model_name}_{prompt_type}_\" if \"clip\" in model_name else f\"{model_name}_\"\n",
    "#ckpt_dir_name += f\"{input_size}_{reduction}_{truncation}_{granularity}_\"\n",
    "#ckpt_dir_name += f\"{weight_count_loss}_{count_loss}\"\n",
    "ckpt_dir_name = 'NWPU_CLIP_ViT_B_16_Word'\n",
    "\n",
    "\n",
    "ckpt_path = os.path.join(\n",
    "    parent_dir,\n",
    "    \"checkpoints\",\n",
    "    ckpt_dir_name,\n",
    "    \"best_mae.pth\"  # select the weight file that you want to test\n",
    ")\n",
    "\n",
    "#ckpt_dir_name = f\"{model_name}_{prompt_type}_\" if \"clip\" in model_name else f\"{model_name}_\"\n",
    "#ckpt_dir_name += f\"{input_size}_{reduction}_{truncation}_{granularity}_\"\n",
    "#ckpt_dir_name += f\"{weight_count_loss}_{count_loss}\"\n",
    "\n",
    "#ckpt_path = os.path.join(\n",
    "#    parent_dir,\n",
    "#    \"checkpoints\",\n",
    "#    \"nwpu\",\n",
    "#    ckpt_dir_name,\n",
    "#    \"best_mae_0.pth\"  # select the weight file that you want to test\n",
    "#)\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "dataset = datasets.NWPUTest(transforms=None, return_filename=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTE CODIGO TARDA COMO UN DIA ENTERO, YA QUE SON 1500 IMAGENES. (No usar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Sliding window prediction.\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m         pred_density \u001b[38;5;241m=\u001b[39m \u001b[43msliding_window_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m         pred_density \u001b[38;5;241m=\u001b[39m model(image)\n",
      "File \u001b[1;32m~\\Desktop\\UNI\\0 MASTER Data Science\\TFM\\CLIP-EBC-main\\utils\\eval_utils.py:75\u001b[0m, in \u001b[0;36msliding_window_predict\u001b[1;34m(model, image, window_size, stride)\u001b[0m\n\u001b[0;32m     73\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 75\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# assemble the density map\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\UNI\\0 MASTER Data Science\\TFM\\CLIP-EBC-main\\models\\clip\\model.py:194\u001b[0m, in \u001b[0;36mCLIP_EBC.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Tuple[Tensor, Tensor]]:\n\u001b[0;32m    192\u001b[0m     device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m--> 194\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_encoder(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;129;01min\u001b[39;00m resnet_backbones \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_vpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_reduction:\n\u001b[0;32m    196\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_reduction \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\UNI\\0 MASTER Data Science\\TFM\\CLIP-EBC-main\\models\\clip\\model.py:171\u001b[0m, in \u001b[0;36mCLIP_EBC._forward_vpt\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    164\u001b[0m image_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[0;32m    165\u001b[0m     image_features[:\u001b[38;5;241m1\u001b[39m, :, :],  \u001b[38;5;66;03m# CLS token\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     vpt,\n\u001b[0;32m    167\u001b[0m     image_features[\u001b[38;5;241m1\u001b[39m:, :, :],\n\u001b[0;32m    168\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# transformer\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# disassemble\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_encoder_depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\UNI\\0 MASTER Data Science\\TFM\\CLIP-EBC-main\\models\\clip\\_clip\\blocks.py:41\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     40\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x))\n\u001b[1;32m---> 41\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CLIP\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\UNI\\0 MASTER Data Science\\TFM\\CLIP-EBC-main\\models\\clip\\_clip\\blocks.py:19\u001b[0m, in \u001b[0;36mQuickGELU.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.702\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h16_nwpu_df_eval = pd.DataFrame()\n",
    "imagenes_recorridas = 0\n",
    "for k in range(dataset.__len__()):\n",
    "    image, image_path = dataset[k]\n",
    "    print(k)\n",
    "    imagenes_recorridas += 1\n",
    "\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    original_image = image\n",
    "    image_height, image_width = image.shape[-2:]\n",
    "    #image = image.to(device)\n",
    "    image_name = os.path.basename(image_path[0])\n",
    "\n",
    "    #Recortar la imagen antes de evaluar el modelo (NO SE SI EL STRIDE IMPORTA O NO POR LA SLIDING WINDOW)\n",
    "    N = 16 #NUMBER OF POINTS TO CONSIDER IN THE OPTIMAL POINT SET (tendre que hacer un bucle sobre range(N) para predecir modelo en cada recorte)\n",
    "    pointset = hinrichs[N]\n",
    "    cuentas = np.array([])\n",
    "    \n",
    "    for i in range(N): #Aqui deberia hacer bucle para cada punto...\n",
    "        point = pointset[i]\n",
    "        left = math.floor(point[0]*image_width)\n",
    "        right = math.floor((point[0]+1/N)*image_width)\n",
    "        bottom = math.floor(point[1]*image_height)\n",
    "        top = math.floor((point[1]+1/N)*image_height)\n",
    "        #Recorto la imagen tq la \"\"\"\"\"\"\"\"esquina inferior izquierda\"\"\"\"\"\"\"\"\"\" del recorte es el punto óptimo del pointset\n",
    "        image = original_image[:,:,bottom:top,left:right] #OBS: Tamaño del recorte = máximo tq el recorte no se sobrepone a los demás ni se sale del tamaño\n",
    "        new_image_height, new_image_width = image.shape[-2:]\n",
    "        image = image.to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if stride is not None:  # Sliding window prediction.\n",
    "                pred_density = sliding_window_predict(model, image, window_size, stride)\n",
    "            else:\n",
    "                pred_density = model(image)\n",
    "            pred_count = pred_density.sum().item()\n",
    "            #resized_pred_density = resize_density_map(pred_density, (new_image_height, new_image_width)).cpu()\n",
    "        \n",
    "        #density = density.squeeze().numpy()\n",
    "        #resized_pred_density = resized_pred_density.squeeze().numpy()\n",
    "        #points = points[0].numpy() #EN SHA Y SHB POINTS PARECE SER YA UN ARRAY, EN QNRF DEBO DESCOMENTAR ESTA LINEA Y COMENTAR LA SIGUIENTE\n",
    "        #points = points[0]\n",
    "        cuentas = np.append(cuentas, pred_count)\n",
    "\n",
    "    \n",
    "    h16_nwpu_df_eval.loc[image_name,'Pred_Count'] = N**2 * cuentas.mean() #((image_height*image_width) / ((image_height/N)*(image_width/N))) * cuentas.mean()\n",
    "    h16_nwpu_df_eval.loc[image_name,'Pred_Count_Variance'] = np.var(N**2 * cuentas)\n",
    "    #nwpu_df_eval.loc[image_name,'GT Count'] = len(points) #EN ESTE CASO NO HAY POINTS, COMO CALCULAN ELLOS EL MAE?????????????\n",
    "\n",
    "print('Imagenes en el dataset: ', dataset.__len__())\n",
    "print('Imagenes recorridas: ', imagenes_recorridas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store h16_nwpu_df_eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r h16_nwpu_df_eval \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
